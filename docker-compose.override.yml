version: '3.8'

services:
  spark-yarn-master:
    container_name: da-spark-yarn-master
    build:
      dockerfile: Dockerfile-yarn
      context: .
    image: da-spark-yarn-image
    entrypoint: ['./entrypoint.sh', 'master']
    volumes:
      - ./book_data:/opt/spark/data
      - ./spark_apps:/opt/spark/apps
      - ./include:/usr/local/airflow/include
      - ./apps:/opt/spark-apps
      - ./data:/opt/spark-data
      - hadoop_conf_vol:/opt/hadoop/etc/hadoop
    env_file:
      - .env.spark
    ports:
      - '9090:8080'
      - '9870:9870'
      - '7077:7077'
      - '8088:8088'
      - '4040:4040'
    networks:
      - airflow

  spark-yarn-worker:
#    container_name: da-spark-worker
    image: da-spark-yarn-image
    entrypoint: ['./entrypoint.sh', 'worker']
    depends_on:
      - spark-yarn-master
    env_file:
      - .env.spark
    volumes:
      - ./book_data:/opt/spark/data
      - ./spark_apps:/opt/spark/apps
      - ./include:/usr/local/airflow/include
      - ./apps:/opt/spark-apps
      - ./data:/opt/spark-data
      - hadoop_conf_vol:/opt/hadoop/etc/hadoop
    ports:
      - '8042:8042'
    networks:
      - airflow

  yarn-history-server:
    container_name: da-spark-yarn-history
    image: da-spark-yarn-image
    entrypoint: ['./entrypoint.sh', 'history']
    depends_on:
      - spark-yarn-master
    env_file:
      - .env.spark
    ports:
      - '18080:18080'
    networks:
      - airflow
  
  scheduler:
    volumes:
      - hadoop_conf_vol:/opt/hadoop/etc/hadoop

  triggerer:
    volumes:
      - hadoop_conf_vol:/opt/hadoop/etc/hadoop
  

volumes:
  hadoop_conf_vol:
